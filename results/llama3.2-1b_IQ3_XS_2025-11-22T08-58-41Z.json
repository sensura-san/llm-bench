[
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ3_XS.gguf",
    "model_type": "llama 1B IQ3_XS - 3.3 bpw",
    "model_size": 613281920,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2025-11-22T08:58:41Z",
    "avg_ns": 90853279813,
    "stddev_ns": 5933781,
    "avg_ts": 5.63546,
    "stddev_ts": 0.000368,
    "samples_ns": [
      90854319753,
      90847743320,
      90862921457,
      90851912996,
      90849501539
    ],
    "samples_ts": [
      5.6354,
      5.6358,
      5.63486,
      5.63554,
      5.63569
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ3_XS.gguf",
    "model_type": "llama 1B IQ3_XS - 3.3 bpw",
    "model_size": 613281920,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T09:07:46Z",
    "avg_ns": 32563615012,
    "stddev_ns": 8810868,
    "avg_ts": 3.930768,
    "stddev_ts": 0.001063,
    "samples_ns": [
      32567491287,
      32563234241,
      32554927373,
      32576363430,
      32556058733
    ],
    "samples_ts": [
      3.9303,
      3.93081,
      3.93182,
      3.92923,
      3.93168
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ3_XS.gguf",
    "model_type": "llama 1B IQ3_XS - 3.3 bpw",
    "model_size": 613281920,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T09:10:29Z",
    "avg_ns": 125176098252,
    "stddev_ns": 11404512,
    "avg_ts": 5.112797,
    "stddev_ts": 0.000465,
    "samples_ns": [
      125193459818,
      125179962825,
      125167374516,
      125164915887,
      125174778218
    ],
    "samples_ts": [
      5.11209,
      5.11264,
      5.11315,
      5.11325,
      5.11285
    ]
  }
]