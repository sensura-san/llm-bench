[
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-F16.gguf",
    "model_type": "llama 1B F16",
    "model_size": 2471764096,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2025-11-22T07:53:28Z",
    "avg_ns": 102028783723,
    "stddev_ns": 43382129,
    "avg_ts": 5.018192,
    "stddev_ts": 0.002134,
    "samples_ns": [
      101959332234,
      102026863001,
      102037413000,
      102078294043,
      102042016337
    ],
    "samples_ts": [
      5.02161,
      5.01829,
      5.01777,
      5.01576,
      5.01754
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-F16.gguf",
    "model_type": "llama 1B F16",
    "model_size": 2471764096,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T08:03:41Z",
    "avg_ns": 86676777527,
    "stddev_ns": 32629340,
    "avg_ts": 1.476751,
    "stddev_ts": 0.000556,
    "samples_ns": [
      86730981369,
      86665472868,
      86662850027,
      86679301526,
      86645281848
    ],
    "samples_ts": [
      1.47583,
      1.47694,
      1.47699,
      1.47671,
      1.47729
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-F16.gguf",
    "model_type": "llama 1B F16",
    "model_size": 2471764096,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T08:10:55Z",
    "avg_ns": 190781692740,
    "stddev_ns": 62097013,
    "avg_ts": 3.35462,
    "stddev_ts": 0.001092,
    "samples_ns": [
      190783996936,
      190882892206,
      190776108738,
      190745974480,
      190719491344
    ],
    "samples_ts": [
      3.35458,
      3.35284,
      3.35472,
      3.35525,
      3.35571
    ]
  }
]