[
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ4_NL.gguf",
    "model_type": "llama 1B IQ4_NL - 4.5 bpw",
    "model_size": 769388672,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2025-11-22T09:24:45Z",
    "avg_ns": 51673061562,
    "stddev_ns": 7949947,
    "avg_ts": 9.908451,
    "stddev_ts": 0.001525,
    "samples_ns": [
      51675238859,
      51660234518,
      51671302827,
      51680580071,
      51677951535
    ],
    "samples_ts": [
      9.90803,
      9.91091,
      9.90879,
      9.90701,
      9.90751
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ4_NL.gguf",
    "model_type": "llama 1B IQ4_NL - 4.5 bpw",
    "model_size": 769388672,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T09:29:55Z",
    "avg_ns": 27999246000,
    "stddev_ns": 3976754,
    "avg_ts": 4.571552,
    "stddev_ts": 0.000649,
    "samples_ns": [
      28005367733,
      27998054186,
      27998170161,
      27994520222,
      28000117700
    ],
    "samples_ts": [
      4.57055,
      4.57175,
      4.57173,
      4.57232,
      4.57141
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ4_NL.gguf",
    "model_type": "llama 1B IQ4_NL - 4.5 bpw",
    "model_size": 769388672,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T09:32:15Z",
    "avg_ns": 81616482682,
    "stddev_ns": 21842972,
    "avg_ts": 7.841554,
    "stddev_ts": 0.002098,
    "samples_ns": [
      81633336977,
      81589708541,
      81617681690,
      81600015403,
      81641670802
    ],
    "samples_ts": [
      7.83993,
      7.84413,
      7.84144,
      7.84314,
      7.83913
    ]
  }
]