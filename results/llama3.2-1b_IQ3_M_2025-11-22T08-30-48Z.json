[
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ3_M.gguf",
    "model_type": "llama 1B IQ3_S mix - 3.66 bpw",
    "model_size": 649457792,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 0,
    "n_depth": 0,
    "test_time": "2025-11-22T08:30:48Z",
    "avg_ns": 98271981006,
    "stddev_ns": 5891140,
    "avg_ts": 5.21003,
    "stddev_ts": 0.000312,
    "samples_ns": [
      98264115098,
      98278203106,
      98268092140,
      98272822056,
      98276672632
    ],
    "samples_ts": [
      5.21045,
      5.2097,
      5.21024,
      5.20999,
      5.20978
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ3_M.gguf",
    "model_type": "llama 1B IQ3_S mix - 3.66 bpw",
    "model_size": 649457792,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 0,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T08:40:38Z",
    "avg_ns": 34755122987,
    "stddev_ns": 44310321,
    "avg_ts": 3.682915,
    "stddev_ts": 0.004688,
    "samples_ns": [
      34833787457,
      34732565317,
      34732088012,
      34744871169,
      34732302983
    ],
    "samples_ts": [
      3.67459,
      3.6853,
      3.68535,
      3.684,
      3.68533
    ]
  },
  {
    "build_commit": "f40a2e5f1",
    "build_number": 7095,
    "cpu_info": "CPU",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/llama3.2-1b/llama3.2-1b-IQ3_M.gguf",
    "model_type": "llama 1B IQ3_S mix - 3.66 bpw",
    "model_size": 649457792,
    "model_n_params": 1235814432,
    "n_batch": 2048,
    "n_ubatch": 512,
    "n_threads": 4,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "n_cpu_moe": 0,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "devices": "auto",
    "tensor_split": "0.00",
    "tensor_buft_overrides": "none",
    "use_mmap": true,
    "embeddings": false,
    "no_op_offload": 0,
    "no_host": false,
    "n_prompt": 512,
    "n_gen": 128,
    "n_depth": 0,
    "test_time": "2025-11-22T08:43:32Z",
    "avg_ns": 134902905290,
    "stddev_ns": 14699478,
    "avg_ts": 4.744153,
    "stddev_ts": 0.000517,
    "samples_ns": [
      134919802138,
      134881525751,
      134896931702,
      134904242380,
      134912024483
    ],
    "samples_ts": [
      4.74356,
      4.7449,
      4.74436,
      4.74411,
      4.74383
    ]
  }
]